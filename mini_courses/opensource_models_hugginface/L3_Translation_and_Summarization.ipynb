{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6685771",
   "metadata": {},
   "source": [
    "# Lesson 3: Translation and Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7109da",
   "metadata": {},
   "source": [
    "- In the classroom, the libraries are already installed for you.\n",
    "- If you would like to run this code on your own machine, you can install the following:\n",
    "\n",
    "```\n",
    "    !pip install transformers \n",
    "    !pip install torch\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e3e7c9-1437-4784-8a21-cd200bc609a5",
   "metadata": {},
   "source": [
    "- Here is some code that suppresses warning messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782af222-1bea-449a-8dd4-655ad7a7b8ea",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea43ec1",
   "metadata": {},
   "source": [
    "### Build the `translation` pipeline using ü§ó Transformers Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1d46ac9-d665-4690-99a4-43b625e02114",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "014e1c26-df35-406c-8ac2-9789b011c86b",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "translator = pipeline(task=\"translation\",\n",
    "                      model=\"facebook/nllb-200-distilled-600M\",\n",
    "                      torch_dtype=torch.bfloat16) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d8f7a5",
   "metadata": {},
   "source": [
    "NLLB: No Language Left Behind: ['nllb-200-distilled-600M'](https://huggingface.co/facebook/nllb-200-distilled-600M).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "095bd1c5-a96f-4b20-8e9c-601b0b158fd8",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\\\n",
    "My puppy is adorable, \\\n",
    "Your kitten is cute.\n",
    "Her panda is friendly.\n",
    "His llama is thoughtful. \\\n",
    "We all have nice pets!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03d9ebdf-86d8-493b-8757-74b3d1010442",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "text_translated = translator(text,\n",
    "                             src_lang=\"eng_Latn\",\n",
    "                             tgt_lang=\"tel_Telu\")#tel_Telu fra_Latn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711052f5",
   "metadata": {},
   "source": [
    "To choose other languages, you can find the other language codes on the page: [Languages in FLORES-200](https://github.com/facebookresearch/flores/blob/main/flores200/README.md#languages-in-flores-200)\n",
    "\n",
    "For example:\n",
    "- Afrikaans: afr_Latn\n",
    "- Chinese: zho_Hans\n",
    "- Egyptian Arabic: arz_Arab\n",
    "- French: fra_Latn\n",
    "- German: deu_Latn\n",
    "- Greek: ell_Grek\n",
    "- Hindi: hin_Deva\n",
    "- Indonesian: ind_Latn\n",
    "- Italian: ita_Latn\n",
    "- Japanese: jpn_Jpan\n",
    "- Korean: kor_Hang\n",
    "- Persian: pes_Arab\n",
    "- Portuguese: por_Latn\n",
    "- Russian: rus_Cyrl\n",
    "- Spanish: spa_Latn\n",
    "- Swahili: swh_Latn\n",
    "- Thai: tha_Thai\n",
    "- Turkish: tur_Latn\n",
    "- Vietnamese: vie_Latn\n",
    "- Zulu: zul_Latn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4ba07e3-4a5e-4bf2-86a9-498781828eca",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': '‡∞®‡∞æ ‡∞ï‡±Å‡∞ï‡±ç‡∞ï‡∞™‡∞ø‡∞≤‡±ç‡∞≤ ‡∞Æ‡∞®‡±ã‡∞π‡∞∞‡∞Ç‡∞ó‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø, ‡∞Æ‡±Ä ‡∞™‡∞ø‡∞≤‡±ç‡∞≤‡∞ø ‡∞Ö‡∞Ç‡∞¶‡∞Ç‡∞ó‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø. ‡∞Ü‡∞Æ‡±Ü ‡∞™‡∞æ‡∞Ç‡∞°‡∞æ ‡∞∏‡±ç‡∞®‡±á‡∞π‡∞™‡±Ç‡∞∞‡±ç‡∞µ‡∞ï‡∞Ç‡∞ó‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø. ‡∞Ö‡∞§‡∞®‡∞ø ‡∞≤‡∞æ‡∞Æ‡∞æ ‡∞∂‡±ç‡∞∞‡∞¶‡±ç‡∞ß‡∞ó‡∞≤‡∞¶‡∞ø. ‡∞Æ‡∞®‡∞Ç‡∞¶‡∞∞‡∞ø‡∞ï‡±Ä ‡∞Æ‡∞Ç‡∞ö‡∞ø ‡∞™‡±Ü‡∞Ç‡∞™‡±Å‡∞°‡±Å ‡∞ú‡∞Ç‡∞§‡±Å‡∞µ‡±Å‡∞≤‡±Å ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞Ø‡∞ø!'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1a932c8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "text1 = \"\"\"My name is siva and I am from India,working as software engineer\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24f37eb1",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': '‡∞®‡∞æ ‡∞™‡±á‡∞∞‡±Å ‡∞∂‡∞ø‡∞µ ‡∞®‡±á‡∞®‡±Å ‡∞≠‡∞æ‡∞∞‡∞§‡∞¶‡±á‡∞∂‡∞Ç ‡∞®‡±Å‡∞Ç‡∞°‡∞ø ‡∞∏‡∞æ‡∞´‡±ç‡∞ü‡±ç‡∞µ‡±á‡∞∞‡±ç ‡∞á‡∞Ç‡∞ú‡∞®‡±Ä‡∞∞‡±ç ‡∞ó‡∞æ ‡∞™‡∞®‡∞ø‡∞ö‡±á‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞®‡±Å'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_translated = translator(text1,\n",
    "                             src_lang=\"eng_Latn\",\n",
    "                             tgt_lang=\"tel_Telu\")#tel_Telu fra_Latn\n",
    "text_translated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7517649",
   "metadata": {},
   "source": [
    "## Free up some memory before continuing\n",
    "- In order to have enough free memory to run the rest of the code, please run the following to free up memory on the machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c16e5dad-dac0-42e4-9a87-8128a1d49b44",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43cafb3a-51b8-4aae-929c-31d524dec530",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "del translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61d698a7-8ae2-475e-ac46-d768c282b17c",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "423"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fac55f",
   "metadata": {},
   "source": [
    "### Build the `summarization` pipeline using ü§ó Transformers Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b132c646-0c6a-4c57-939a-b3015ea4b76f",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eecf83060f2b41a698b59043875fb7c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378b9986467e427b9a7cee6a10e0cf2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90da46d1ac72440f874f7a603b045628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37342ede4ab84a2183b364995815fd86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed4f276e1bd40fcb51201c28f813a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436f552b37cf419a8f06a48acccba494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarizer = pipeline(task=\"summarization\",\n",
    "                      model=\"facebook/bart-large-cnn\",\n",
    "                      torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca6f847",
   "metadata": {},
   "source": [
    "Model info: ['bart-large-cnn'](https://huggingface.co/facebook/bart-large-cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98276d66-4274-4a2f-b6a7-b4fb839b94f7",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "text = \"\"\"Paris is the capital and most populous city of France, with\n",
    "          an estimated population of 2,175,601 residents as of 2018,\n",
    "          in an area of more than 105 square kilometres (41 square\n",
    "          miles). The City of Paris is the centre and seat of\n",
    "          government of the region and province of √éle-de-France, or\n",
    "          Paris Region, which has an estimated population of\n",
    "          12,174,880, or about 18 percent of the population of France\n",
    "          as of 2017.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d856f193-cbf7-450b-8ae3-42287096e56f",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "summary = summarizer(text,\n",
    "                     min_length=10,\n",
    "                     max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2c79f81-6baf-4f6b-95ee-b1a2072ec073",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Paris is the capital and most populous city of France, with an estimated population of 2,175,601 residents as of 2018. The City of Paris is the centre and seat of the government of the region and province of √éle-de-France.'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca56abc0",
   "metadata": {},
   "source": [
    "### Try it yourself! \n",
    "- Try this model with your own texts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "002c0464-7d37-4b50-b3fe-4099101e2c8b",
   "metadata": {
    "height": 162
   },
   "outputs": [],
   "source": [
    "text2 = \"\"\"Both classic one stage detection methods, like boosted detectors, DPM & more recent methods like SSD evaluate almost 104 to 105 candidate locations per image but only a few locations contain objects (i.e. Foreground) and rest are just background objects. This leads to the class imbalance problem.\n",
    "\n",
    "This imbalance causes two problems ‚Äì\n",
    "\n",
    "Training is inefficient as most locations are easy negatives (meaning that they can be easily classified by the detector as background) that contribute no useful learning.\n",
    "Since easy negatives (detections with high probabilities) account for a large portion of inputs. Although they result in small loss values individually but collectively, they can overwhelm the loss & computed gradients and can lead to degenerated models.\n",
    "In simple words, Focal Loss (FL) is an improved version of Cross-Entropy Loss (CE)  that tries to handle the class imbalance problem by assigning more weights to hard or easily misclassified examples  (i.e. background with noisy texture or partial object or the object of our interest ) and to down-weight easy examples (i.e. Background objects).\n",
    "\n",
    "So Focal Loss reduces the loss contribution from easy examples and increases the importance of correcting misclassified examples.)\n",
    "\n",
    "So, let‚Äôs first understand what Cross-Entropy loss for binary classification.\n",
    ".\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4742fccc",
   "metadata": {
    "height": 78
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Focal Loss is an improved version of Cross-Entropy Loss (CE) It tries to handle the class imbalance problem by assigning more weights to hard or easily misclassified examples and to down-weight easy examples.'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = summarizer(text2,min_length=10,\n",
    "                     max_length=100)\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
